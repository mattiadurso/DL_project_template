{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add src to the notebook path\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "# import from src\n",
    "from utils import *\n",
    "from models.model import *\n",
    "from data.dataset import *\n",
    "from constants import *\n",
    "\n",
    "# import python libraries\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "os.environ['WANDB_API_KEY'] = wandb_key\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = os.getcwd()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "config = load_yaml_as_dict(\"../config/config.yaml\")\n",
    "# Prints the nicely formatted dictionary\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_images = config[\"data_path\"]\n",
    "\n",
    "image_size = (config[\"image_size\"], config[\"image_size\"])\n",
    "transform = T.Compose([\n",
    "        #T.ToPILImage(),\n",
    "        #T.CenterCrop(0.75 * 64),\n",
    "        T.Resize(image_size),\n",
    "        #T.RandomResizedCrop(image_size),\n",
    "        #T.RandomHorizontalFlip(),\n",
    "        T.ToTensor()\n",
    "        ])\n",
    "\n",
    "train_set = MP3DL_Dataset(testing_images, transform, load_all=True)\n",
    "train_loader = DataLoader(train_set, batch_size=config[\"training\"][\"batch_size\"], shuffle=config[\"training\"][\"shuffle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = select_loss_function(config[\"training\"][\"loss_fn\"])\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = select_optimizer(model, config[\"training\"][\"optim\"], learning_rate=config[\"training\"][\"lr\"], momentum=0.9)\n",
    "scheduler = None #select_scheduler(config[\"training\"][\"scheduler\"], optimizer, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(project=\"my-awesome-project\", config=config, mode=\"online\", settings=wandb.Settings(disable_job_creation=True)) # mode: [online, disabled]\n",
    "    \n",
    "# simulate training\n",
    "epochs = config[\"training\"][\"epochs\"]\n",
    "\n",
    "model = model.to(device)\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    loss = train_one_epoch(model, train_loader, loss_fn, optimizer, scheduler)\n",
    "    #acc  = evaluate(model, validation_loader)\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"loss\": loss})\n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
